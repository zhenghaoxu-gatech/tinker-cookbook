"""
Utilities for parsing Think RM model outputs.

We adopt the same parsing rules used in the VERL recipe: the model is expected
to optionally produce a `<think>...</think>` reasoning trace followed by a
final `<label>X</label>` tag where `X` is 0, 1, or 2. Only the portion after
the last closing `</think>` tag is considered when extracting the label.
"""

from __future__ import annotations

import re
from typing import Optional

CHOICE_ALIASES = {
    "response 1": "response_1",
    "response1": "response_1",
    "assistant a": "response_1",
    "1": "response_1",
    "option 1": "response_1",
    "choice 1": "response_1",
    "a": "response_1",
    "response 2": "response_2",
    "response2": "response_2",
    "assistant b": "response_2",
    "2": "response_2",
    "option 2": "response_2",
    "choice 2": "response_2",
    "b": "response_2",
    "tie": "tie",
    "draw": "tie",
    "equal": "tie",
    "0": "tie",
}

THINK_CLOSE_RE = re.compile(r"</think\s*>", re.IGNORECASE)
LABEL_TAG_RE = re.compile(r"<label>\s*([012])\s*</label>", re.IGNORECASE)


def normalise_choice(raw: str | None) -> Optional[str]:
    """Convert free-form labels to the canonical identifiers."""
    if raw is None:
        return None
    cleaned = raw.strip().lower()
    cleaned = cleaned.replace("_", " ").replace("-", " ")
    cleaned = re.sub(r"[^a-z0-9\s]", "", cleaned)
    cleaned = re.sub(r"\s+", " ", cleaned)
    if cleaned in CHOICE_ALIASES:
        return CHOICE_ALIASES[cleaned]
    if "response" in cleaned and "1" in cleaned:
        return "response_1"
    if "response" in cleaned and "2" in cleaned:
        return "response_2"
    if "tie" in cleaned or "equal" in cleaned or "same" in cleaned:
        return "tie"
    return None


def _segment_after_last_think(text: str, exclude_think: bool = True) -> Optional[str]:
    """Return the substring strictly after the last closing </think> (if requested)."""
    if not exclude_think:
        return text

    last_close = None
    for match in THINK_CLOSE_RE.finditer(text):
        last_close = match

    if last_close is None:
        return None

    segment = text[last_close.end() :]
    # Remove stray </think> occurrences to avoid confusing the label search.
    segment = THINK_CLOSE_RE.sub("", segment)
    return segment


def parse_preference(output: str, *, from_thinking_model: bool = True) -> Optional[str]:
    """
    Extract the final preference decision from a model output.

    Args:
        output: Raw text generated by the model.
        from_thinking_model: Whether to discard everything before the last </think>.

    Returns:
        "response_1", "response_2", "tie", or None if no valid label was found.
    """
    visible = _segment_after_last_think(output, exclude_think=from_thinking_model)
    if visible is None:
        return None

    last_digit = None
    for match in LABEL_TAG_RE.finditer(visible):
        last_digit = match.group(1)

    if last_digit is None:
        return None

    if last_digit == "1":
        return "response_1"
    if last_digit == "2":
        return "response_2"
    return "tie"
